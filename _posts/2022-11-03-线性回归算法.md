线性回归算法-linear Regression

# 概述

## 引入

线性回归是最基础的机器学习模型和统计模型，当我刚开始接触机器学习的时候，我感觉线性回归模型不过是高中数学课上学的入门知识，可能在工业或商业领域可用性不强；但是在准备这一章的时候我看了很多介绍线性回归的文章，其实线性回归依然是工业界使用最广泛的模型。对于工业界，他们面临最棘手的问题不是数据不足，而是算力紧张。因此正需要那种即需要大量数据又计算简单的算法模型。因为数据量够多，线性回归这种简单的模型也可以产生不错的效果。

![img](https://ckxk6c244x.feishu.cn/space/api/box/stream/download/asynccode/?code=M2E1M2VhYTZkNjNjMjlkMzE1NGQ2MmRiZjkyMDFjZWNfR1VaZ2x2SUR4MWxHV04wWHM0RU9jNENzZE1wY2VqWDBfVG9rZW46Ym94Y25aNDNZaHRkamplVmtUNzY4VHU4bW1oXzE2Njc0NzIxOTc6MTY2NzQ3NTc5N19WNA)

> *哥本哈根学派科学家波尔，海森堡认为世间一切的事都符合某种概率分布而不是因果，可以用概率模型来表示一切规律*

## 模型

线性回归分析是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，“线性”限制的是parameter，而非feature（参数）。

当我们拿到数据集的时候，我们将每行数据绘制成散点图，然后发现似乎两个特征之间呈现出一种正相关关系，那我们便可以选择一条线性函数来很好的拟合已知数据并预测未知数据

- 这里选取的模型非常简单，线性回归模型首先想到的是一条直线，我们中学时学过用y=wx+b来作为这条直线的表达式，当有多个特征（属性）d参与模型时，那我们可以得到一个组合

- - ​                         $$$$f(x)=W_1X_1+W_2X_2+.....W_dX_d+b $$$$

  -  写成向量形式

  - ​                                                    $$$$f(x)= W^T+b $$$$

![img](https://ckxk6c244x.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjBjMjk2NjBiOWIyZDRhNzdjMTVmYWUwM2QyYmU3MTdfT0s2azFub0hrYzZWZ29JeDNyT1VUdTZVV2wyYWRHTW9fVG9rZW46Ym94Y25xazZFb2doY0o3OEJTRTU1NzNMY3JxXzE2Njc0NzIxOTc6MTY2NzQ3NTc5N19WNA)

只需要求出w和b的值，那么模型就求解完成。

- ## 损失函数

- -   对w和b值进行求解时，首先我们要给计算机制定一个目标，要确定一个定量化的目标函数式，无论我们选择什么样的模型，最终都是得出了一个预测值 ，对比已有的真实值y，数据量n，我们可以很自然的将损失函数定义如下：                                               

  - ​                                                  $$$$L=\quad\tfrac{1}{n}\quad\sum_{i=1}^{n}(f(x_i)-y_i)^2 $$$$

即预测值与真实值之间的平均距离的平方

# 求解方法

# 代码实现

# 两种方法对比
